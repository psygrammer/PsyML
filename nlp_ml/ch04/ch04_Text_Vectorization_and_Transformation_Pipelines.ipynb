{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4. Text Vectorization and Transformation Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머 / 싸이ML - NLP [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* Words in Space\n",
    "    - Frequency Vectors\n",
    "        - With NLTK\n",
    "        - In Scikit-Learn\n",
    "        - The Gensim way\n",
    "    - One-Hot Encoding\n",
    "        - With NLTK\n",
    "        - In Scikit-Learn\n",
    "        - The Gensim way\n",
    "    - Term Frequency-Inverse Document Frequency\n",
    "        - With NLTK\n",
    "        - In Scikit-Learn\n",
    "        - The Gensim way\n",
    "    - Distributed Representation\n",
    "        - The Gensim way\n",
    "* The Scikit-Learn API\n",
    "    - The BaseEstimator Interface\n",
    "    - Extending TransformerMixin\n",
    "        - Creating a custom Gensim vectorization transformer\n",
    "        - Creating a custom text normalization transformer\n",
    "* Pipelines\n",
    "    - Pipeline Basics\n",
    "    - Grid Search for Hyperparameter Optimization\n",
    "    - Enriching Feature Extraction with Feature Unions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words in Space\n",
    "* Frequency Vectors\n",
    "* One-Hot Encoding\n",
    "* Term Frequency-Inverse Document Frequency\n",
    "* Distributed Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/cap01.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize 함수를 만들어서 corpus에 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text) :\n",
    "    pass # <- 코딩!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The corpus object\n",
    "corpus = [\n",
    "    # 코딩!!\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The elephant sneezed at the sight of potatoes.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bats can see via echolocation. See the bat sight sneeze!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wondering, she opened the door to the studio.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elephant sneezed at the sight of potatoes.\n",
      "Bats can see via echolocation. See the bat sight sneeze!\n",
      "Wondering, she opened the door to the studio.\n"
     ]
    }
   ],
   "source": [
    "for text in corpus :\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'elephant', 'sneezed', 'at', 'the', 'sight', 'of', 'potatoes.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 코퍼스 리더 클래스를 통해, 코퍼스 접근(파일 읽기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 현재 위치에서 corpus라는 이름으로 디렉토리를 만들고, \n",
    "# 1.txt 파일에 다음 문장들 저장\n",
    "# \"The elephant sneezed at the sight of potatoes.\"\n",
    "# \"Bats can see via echolocation. See the bat sight sneeze!\"\n",
    "# \"Wondering, she opened the door to the studio.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextCorpusReader(object):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        pass # <- 코딩!!\n",
    "    \n",
    "\n",
    "    def docs(self):\n",
    "        pass # <- 코딩!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_dir_path = \n",
    "reader = TextCorpusReader(paht=corpus_dir_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "lst = os.listdir('./corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt\n"
     ]
    }
   ],
   "source": [
    "for fn in lst : \n",
    "    if 'txt' in fn :\n",
    "        print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./corpus/1.txt']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dir_path = './corpus'\n",
    "fn_list = # 코딩!!\n",
    "fn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader.docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = reader.docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The elephant sneezed at the sight of potatoes.',\n",
       " 'Bats can see via echolocation. See the bat sight sneeze!',\n",
       " 'Wondering, she opened the door to the studio.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib as imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object tokenize at 0x7fd41effbe08>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 패키지를 만들어보자. mynlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir(mynlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 지금까지 만든 코퍼스 리더와 tokenize 함수를 패키지에 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib as imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp.reload(mynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir(mynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_dir_path = './corpus'\n",
    "reader = mynlp.TextCorpusReader(paht=corpus_dir_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = reader.docs\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'elephant', 'sneezed', 'at', 'the', 'sight', 'of', 'potatoes.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynlp.tokenize(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize 함수를 제너레이터를 반환하는 형태로 바꾸자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp.reload(mynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mynlp.tokenize(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for token in mynlp.tokenize(corpus[0]) :\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize 함수를 nltk를 이용해서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp.reload(mynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mynlp.tokenize(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "elephant\n",
      "sneezed\n",
      "at\n",
      "the\n",
      "sight\n",
      "of\n",
      "potatoes.\n"
     ]
    }
   ],
   "source": [
    "for token in mynlp.tokenize(corpus[0]) :\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'eleph', 'sneez', 'at', 'the', 'sight', 'of', 'potato']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in mynlp.tokenize(corpus[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elephant sneezed at the sight of potatoes.\n",
      "<generator object tokenize at 0x7fd45c188b48>\n",
      "Bats can see via echolocation. See the bat sight sneeze!\n",
      "<generator object tokenize at 0x7fd45c188b48>\n",
      "Wondering, she opened the door to the studio.\n",
      "<generator object tokenize at 0x7fd45c188b48>\n"
     ]
    }
   ],
   "source": [
    "for text in corpus :\n",
    "    print(text)\n",
    "    print(mynlp.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<generator object tokenize at 0x7fd41f1bd830>,\n",
       " <generator object tokenize at 0x7fd41f1bd780>,\n",
       " <generator object tokenize at 0x7fd41f1bd728>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mynlp.tokenize(text) for text in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'eleph', 'sneez', 'at', 'the', 'sight', 'of', 'potato'], ['bat', 'can', 'see', 'via', 'echoloc', 'see', 'the', 'bat', 'sight', 'sneez'], ['wonder', 'she', 'open', 'the', 'door', 'to', 'the', 'studio']]\n"
     ]
    }
   ],
   "source": [
    "total_token_arr = []\n",
    "\n",
    "for text in corpus :\n",
    "    # 코딩!!\n",
    "    \n",
    "print(total_token_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'eleph', 'sneez', 'at', 'the', 'sight', 'of', 'potato'], ['bat', 'can', 'see', 'via', 'echoloc', 'see', 'the', 'bat', 'sight', 'sneez'], ['wonder', 'she', 'open', 'the', 'door', 'to', 'the', 'studio']]\n"
     ]
    }
   ],
   "source": [
    "total_token_arr = # 코딩!!\n",
    "print(total_token_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Vectors\n",
    "* With NLTK\n",
    "* In Scikit-Learn\n",
    "* The Gensim way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/cap02.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The NLTK frequency vectorize method\n",
    "def vectorize(doc):\n",
    "    pass # <- 코딩!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The elephant sneezed at the sight of potatoes.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = corpus[0]\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 토큰 카운팅하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = defaultdict(int)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for token in mynlp.tokenize(doc) :\n",
    "    # 코딩!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'at': 1,\n",
       "             'eleph': 1,\n",
       "             'of': 1,\n",
       "             'potato': 1,\n",
       "             'sight': 1,\n",
       "             'sneez': 1,\n",
       "             'the': 2})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'at': 1,\n",
       "             'eleph': 1,\n",
       "             'of': 1,\n",
       "             'potato': 1,\n",
       "             'sight': 1,\n",
       "             'sneez': 1,\n",
       "             'the': 2})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 패키지에 vectorize 함수를 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp.reload(mynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'bat': 2,\n",
       "             'can': 1,\n",
       "             'echoloc': 1,\n",
       "             'see': 2,\n",
       "             'sight': 1,\n",
       "             'sneez': 1,\n",
       "             'the': 1,\n",
       "             'via': 1})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = corpus[1]\n",
    "mynlp.vectorize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 코퍼스 전체에 vectorize 함수를 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7fd41ef93518>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(mynlp.vectorize, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[defaultdict(int,\n",
       "             {'at': 1,\n",
       "              'eleph': 1,\n",
       "              'of': 1,\n",
       "              'potato': 1,\n",
       "              'sight': 1,\n",
       "              'sneez': 1,\n",
       "              'the': 2}),\n",
       " defaultdict(int,\n",
       "             {'bat': 2,\n",
       "              'can': 1,\n",
       "              'echoloc': 1,\n",
       "              'see': 2,\n",
       "              'sight': 1,\n",
       "              'sneez': 1,\n",
       "              'the': 1,\n",
       "              'via': 1}),\n",
       " defaultdict(int,\n",
       "             {'door': 1,\n",
       "              'open': 1,\n",
       "              'she': 1,\n",
       "              'studio': 1,\n",
       "              'the': 2,\n",
       "              'to': 1,\n",
       "              'wonder': 1})]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(mynlp.vectorize, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = map(mynlp.vectorize, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7fd41efa0080>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[defaultdict(int,\n",
       "             {'at': 1,\n",
       "              'eleph': 1,\n",
       "              'of': 1,\n",
       "              'potato': 1,\n",
       "              'sight': 1,\n",
       "              'sneez': 1,\n",
       "              'the': 2}),\n",
       " defaultdict(int,\n",
       "             {'bat': 2,\n",
       "              'can': 1,\n",
       "              'echoloc': 1,\n",
       "              'see': 2,\n",
       "              'sight': 1,\n",
       "              'sneez': 1,\n",
       "              'the': 1,\n",
       "              'via': 1}),\n",
       " defaultdict(int,\n",
       "             {'door': 1,\n",
       "              'open': 1,\n",
       "              'she': 1,\n",
       "              'studio': 1,\n",
       "              'the': 2,\n",
       "              'to': 1,\n",
       "              'wonder': 1})]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 패키지에 nltk_frequency_vectorize 함수를 만들어서 코퍼스에 대해 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mynlp' from '/home/jovyan/work/nlp_ml/ch04/mynlp.py'>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(mynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = mynlp.nltk_frequency_vectorize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[defaultdict(int,\n",
       "             {'at': 1,\n",
       "              'eleph': 1,\n",
       "              'of': 1,\n",
       "              'potato': 1,\n",
       "              'sight': 1,\n",
       "              'sneez': 1,\n",
       "              'the': 2}),\n",
       " defaultdict(int,\n",
       "             {'bat': 2,\n",
       "              'can': 1,\n",
       "              'echoloc': 1,\n",
       "              'see': 2,\n",
       "              'sight': 1,\n",
       "              'sneez': 1,\n",
       "              'the': 1,\n",
       "              'via': 1}),\n",
       " defaultdict(int,\n",
       "             {'door': 1,\n",
       "              'open': 1,\n",
       "              'she': 1,\n",
       "              'studio': 1,\n",
       "              'the': 2,\n",
       "              'to': 1,\n",
       "              'wonder': 1})]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = # 코딩 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = # 코딩 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 23 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'at': 0,\n",
       " 'bat': 1,\n",
       " 'bats': 2,\n",
       " 'can': 3,\n",
       " 'door': 4,\n",
       " 'echolocation': 5,\n",
       " 'elephant': 6,\n",
       " 'of': 7,\n",
       " 'opened': 8,\n",
       " 'potatoes': 9,\n",
       " 'see': 10,\n",
       " 'she': 11,\n",
       " 'sight': 12,\n",
       " 'sneeze': 13,\n",
       " 'sneezed': 14,\n",
       " 'studio': 15,\n",
       " 'the': 16,\n",
       " 'to': 17,\n",
       " 'via': 18,\n",
       " 'wondering': 19}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 2, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2, 1, 0, 1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 패키지에 sklearn_frequency_vectorize 함수를 만들어서 코퍼스에 대해 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mynlp' from '/home/jovyan/work/nlp_ml/ch04/mynlp.py'>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(mynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = mynlp.sklearn_frequency_vectorize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 23 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Gensim way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_g = # 코딩 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'eleph', 'sneez', 'at', 'the', 'sight', 'of', 'potato'],\n",
       " ['bat',\n",
       "  'can',\n",
       "  'see',\n",
       "  'via',\n",
       "  'echoloc',\n",
       "  'see',\n",
       "  'the',\n",
       "  'bat',\n",
       "  'sight',\n",
       "  'sneez'],\n",
       " ['wonder', 'she', 'open', 'the', 'door', 'to', 'the', 'studio']]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2word = # 코딩 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x7fd43326c208>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'at': 0,\n",
       " 'bat': 7,\n",
       " 'can': 8,\n",
       " 'door': 12,\n",
       " 'echoloc': 9,\n",
       " 'eleph': 1,\n",
       " 'of': 2,\n",
       " 'open': 13,\n",
       " 'potato': 3,\n",
       " 'see': 10,\n",
       " 'she': 14,\n",
       " 'sight': 4,\n",
       " 'sneez': 5,\n",
       " 'studio': 15,\n",
       " 'the': 6,\n",
       " 'to': 16,\n",
       " 'via': 11,\n",
       " 'wonder': 17}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = # 코딩 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2)],\n",
       " [(4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 2), (11, 1)],\n",
       " [(6, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)]]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 패키지에 gensim_frequency_vectorize 함수를 만들어서 코퍼스에 대해 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mynlp' from '/home/jovyan/work/nlp_ml/ch04/mynlp.py'>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(mynlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectors = mynlp.gensim_frequency_vectorize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2)],\n",
       " [(4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 2), (11, 1)],\n",
       " [(6, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)]]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding\n",
    "* With NLTK\n",
    "* In Scikit-Learn\n",
    "* The Gensim way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Gensim way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency-Inverse Document Frequency\n",
    "* With NLTK\n",
    "* In Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Gensim way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Representation\n",
    "* The Gensim way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Gensim way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Scikit-Learn API\n",
    "* The BaseEstimator Interface\n",
    "* Extending TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The BaseEstimator Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending TransformerMixin\n",
    "* Creating a custom Gensim vectorization transformer\n",
    "* Creating a custom text normalization transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a custom Gensim vectorization transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a custom text normalization transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "* Pipeline Basics\n",
    "* Grid Search for Hyperparameter Optimization\n",
    "* Enriching Feature Extraction with Feature Unions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enriching Feature Extraction with Feature Unions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
